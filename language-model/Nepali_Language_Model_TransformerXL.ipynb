{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-nepali/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import NepaliTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inltk.tokenizer.NepaliTokenizer"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NepaliTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NepaliTokenizer(BaseTokenizer):\n",
    "#     def __init__(self, lang:str):\n",
    "#         self.lang = lang\n",
    "#         self.sp = spm.SentencePieceProcessor()\n",
    "#         self.sp.Load(str(path/\"../tokenizer/nepali_lm.model\"))\n",
    "        \n",
    "#     def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/nepali_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(15000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '▁',\n",
       " 'को',\n",
       " '।',\n",
       " ',',\n",
       " 'मा',\n",
       " '▁।',\n",
       " '▁र',\n",
       " '.',\n",
       " 'ले',\n",
       " 'का',\n",
       " '▁छ',\n",
       " '▁हो',\n",
       " 'लाई',\n",
       " '▁•',\n",
       " '▁यो',\n",
       " '▁q',\n",
       " '▁�']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15,000 is the vocab size that we chose in sentencepiece\n",
    "nepali_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=NepaliTokenizer, lang='ne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=nepali_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁नाच ▁हो । ▁ x x b os ▁बाल ▁विकास ▁भन्नाले ▁बालबालिका को ▁शारीरिक , ▁मानसिक , ▁सं वे ग ात्मक ▁र ▁नैतिक ▁आदि ▁पक्ष ▁आउने ▁सम्पूर्ण ▁परिमाण ात्मक ▁र ▁गुण ात्मक ▁परि बर् तन को ▁सिंग ो ▁प्रक्रिया ▁हो ▁। ▁ x x b os ▁काल ेश्वर ▁महादेव लाई ▁ललितपुर को ▁प ्याङ ▁वा सि ▁ हरू ▁आफ्ना ▁आ रा ध्य देव का ▁रूपमा ▁लिने ▁गर्दछन् । ▁त्यस्तै ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>▁the &lt;unk&gt; ▁e p ic &lt;unk&gt; ▁e n co un ter &lt;unk&gt; at ▁ &lt;unk&gt; trans f or m ed ▁the &lt;unk&gt; ▁m id d le &lt;unk&gt; ▁e a st . &lt;unk&gt; &lt;unk&gt; ch ok en &lt;unk&gt; ok s . ▁प &lt;unk&gt; ▁26 0 . ▁ . ▁http s : ▁/ ▁/ ▁ book s . go o g le . es ▁/ ▁ book s ? id = n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁श्री ▁राम ▁का ▁साथै ▁आ द्य ▁शक्ति ▁नव ▁दुर्गा ▁देवीको ▁पनि ▁पूजा ▁हुन्छ ▁। ▁त्रेता ▁युगमा ▁चैत्र ▁शुक्ल ▁नवमी का ▁दिन ▁अयोध्या मा ▁जन्म नु ▁भएका ▁श्रीराम ले ▁दानव ीय ▁प्रवृत्ति का ▁रावण को ▁अन्त्य ▁गरी ▁जन ▁कल्याण ▁गरिएको ▁सम्झना मा ▁यो ▁पर्व ▁मनाइन्छ ▁। ▁हिन्दू ▁धर्मावलम्बीहरू ▁रामनवमी का ▁दिन ▁बिहानै ▁नु हाइ धुवा इ ▁गरी ▁राम ▁मन्दिरमा ▁गई ▁पूजा ▁आराधना ▁गर्ने ▁गर्दछन् ▁। ▁यसै ▁क्रममा ▁राजधानी को ▁बत्ति स</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ं त्र ▁मात्र ▁थियो ▁ x x b os ▁फ्रे ञ्च ▁ओपन ▁एउटा ▁मुख्य ▁टेनिस ▁प्रतियोगिता ▁हो ▁जुन ▁बर्षको ▁मे ▁महिना को ▁अन्त्य ▁तथा ▁जुन ▁महिना को ▁पहिलो ▁दुई ▁हप्ता भित्र ▁फ्रान्स को ▁मध्य ▁पेरिस को ▁ स्टेड ▁ रो ले न्ड ▁गार् रो स मा ▁खेल िन्छ ▁। ▁फ्रे ञ्च ▁ओपन ▁बार्षिक ▁टेनिस ▁क्यालेन्डर को ▁दोस्रो ▁ग्र ्यान्ड ▁स् ल्या म ▁र ▁संसार कै ▁प्रमुख ▁क्ले - को र्ट</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁बन्यो ▁र ▁सरकार ▁ पनी ▁माओवादी को ▁बन्यो । सो ▁सरकारका ▁तत्कालीन ▁अर्थमन्त्री ▁बाबुराम ▁भट्टराई ▁र ▁नागरिक ▁उड्डयन ▁तथा ▁पर्यटन ▁मन्त्री ▁हि सिला ▁यम ी ▁द्वारा ▁औ प चार ीक ▁रुपमा ▁यसको ▁उद्घाटन ▁गरियो । त त् पश्चात् ▁यस ▁क्षेत्रको ▁स्थानीय ▁एवं ▁जिल्लाबाट ▁संरक्षण ▁एवं ▁प्र र्व द्व न ▁गर्ने ▁कार्य ▁हुदै ▁आइरहेको ▁छ । वि भिन्न ▁समयमा ▁यहाँ ▁महोत्सव को ▁आयोजना ▁हुदै ▁आइरहे का ▁छन । जू न ▁विशेषगरी</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(15000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=15000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.236090</td>\n",
       "      <td>6.203444</td>\n",
       "      <td>0.177704</td>\n",
       "      <td>08:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.582477</td>\n",
       "      <td>5.552870</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.096238</td>\n",
       "      <td>5.139091</td>\n",
       "      <td>0.242624</td>\n",
       "      <td>08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.822802</td>\n",
       "      <td>4.806278</td>\n",
       "      <td>0.265919</td>\n",
       "      <td>08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.560954</td>\n",
       "      <td>4.614542</td>\n",
       "      <td>0.280274</td>\n",
       "      <td>08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.426813</td>\n",
       "      <td>4.466482</td>\n",
       "      <td>0.291230</td>\n",
       "      <td>08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.279871</td>\n",
       "      <td>4.337081</td>\n",
       "      <td>0.302837</td>\n",
       "      <td>08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.124228</td>\n",
       "      <td>4.226497</td>\n",
       "      <td>0.312392</td>\n",
       "      <td>08:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.077218</td>\n",
       "      <td>4.121408</td>\n",
       "      <td>0.322632</td>\n",
       "      <td>08:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.898239</td>\n",
       "      <td>4.022962</td>\n",
       "      <td>0.334289</td>\n",
       "      <td>08:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.877700</td>\n",
       "      <td>3.912001</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>08:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.701219</td>\n",
       "      <td>3.807258</td>\n",
       "      <td>0.360690</td>\n",
       "      <td>08:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.449376</td>\n",
       "      <td>3.707330</td>\n",
       "      <td>0.375552</td>\n",
       "      <td>08:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.431893</td>\n",
       "      <td>3.617748</td>\n",
       "      <td>0.388643</td>\n",
       "      <td>08:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.247346</td>\n",
       "      <td>3.536784</td>\n",
       "      <td>0.401237</td>\n",
       "      <td>08:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.150140</td>\n",
       "      <td>3.467554</td>\n",
       "      <td>0.412394</td>\n",
       "      <td>08:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.067541</td>\n",
       "      <td>3.418373</td>\n",
       "      <td>0.421274</td>\n",
       "      <td>08:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.923440</td>\n",
       "      <td>3.393434</td>\n",
       "      <td>0.426726</td>\n",
       "      <td>08:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.938976</td>\n",
       "      <td>3.379331</td>\n",
       "      <td>0.429090</td>\n",
       "      <td>08:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.836050</td>\n",
       "      <td>3.378801</td>\n",
       "      <td>0.429403</td>\n",
       "      <td>08:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.1777041107416153.\n",
      "Better model found at epoch 1 with accuracy value: 0.21883007884025574.\n",
      "Better model found at epoch 2 with accuracy value: 0.24262377619743347.\n",
      "Better model found at epoch 3 with accuracy value: 0.26591935753822327.\n",
      "Better model found at epoch 4 with accuracy value: 0.2802739441394806.\n",
      "Better model found at epoch 5 with accuracy value: 0.2912299931049347.\n",
      "Better model found at epoch 6 with accuracy value: 0.3028365671634674.\n",
      "Better model found at epoch 7 with accuracy value: 0.3123922646045685.\n",
      "Better model found at epoch 8 with accuracy value: 0.3226315975189209.\n",
      "Better model found at epoch 9 with accuracy value: 0.3342888057231903.\n",
      "Better model found at epoch 10 with accuracy value: 0.3462657034397125.\n",
      "Better model found at epoch 11 with accuracy value: 0.360690176486969.\n",
      "Better model found at epoch 12 with accuracy value: 0.37555167078971863.\n",
      "Better model found at epoch 13 with accuracy value: 0.3886428773403168.\n",
      "Better model found at epoch 14 with accuracy value: 0.40123698115348816.\n",
      "Better model found at epoch 15 with accuracy value: 0.4123937487602234.\n",
      "Better model found at epoch 16 with accuracy value: 0.4212742745876312.\n",
      "Better model found at epoch 17 with accuracy value: 0.42672601342201233.\n",
      "Better model found at epoch 18 with accuracy value: 0.42908975481987.\n",
      "Better model found at epoch 19 with accuracy value: 0.4294031858444214.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7), callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"अन्तर्राष्ट्रिय खेलमा राष्ट्रिय \"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अन्तर्राष्ट्रिय खेलमा राष्ट्रिय  ▁फुटबल ▁टिम ▁अन्तर्राष्ट्रिय ▁फुटबल ▁प्रतियोगिताहरू मा ▁अन्तर्राष्ट्रिय ▁फुटबल ▁प्रतियोगिताहरू मा ▁अन्तर्राष्ट्रिय ▁फुटबल ▁प्रतियोगिताहरू मा ▁अन्तर्राष्ट्रिय ▁फुटबल ▁प्रतियोगितामा ▁अन्तर्राष्ट्रिय ▁फुटबल को ▁लागि ▁शासकीय ▁निकाय ▁अन्तर्राष्ट्रिय ▁फुटबल ▁संघको ▁नियन्त्रणमा ▁रहेको े ▁छ ▁। ▁यो ▁फिफा ▁ द्वरा ▁मान्यता ▁प्रप्त ▁र ▁एएफसी को\n",
      "अन्तर्राष्ट्रिय खेलमा राष्ट्रिय  ▁स्तर को ▁फुटबल ▁खेल ▁खेलाडीहरू को ▁योगदान को ▁लागि ▁प्रयोग ▁हुने ▁खेल ▁हो । ▁सन् ▁1995 मा ▁अन्तर्राष्ट्रिय ▁स्तर को ▁फुटबल ▁प्रतियोगिता ▁पहिलो ▁पटक ▁आयोजना ▁भएको ▁थियो ▁भने ▁सन् ▁2005 मा ▁अन्तर्राष्ट्रिय ▁स्तर को ▁फुटबल ▁प्रतियोगितामा ▁भाग ▁लिएका ▁थिए ।\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.335576662014443"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.378801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-nepali/language-model')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'NepaliDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15000, 410])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 410)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.160747</td>\n",
       "      <td>0.076773</td>\n",
       "      <td>0.149212</td>\n",
       "      <td>-0.138141</td>\n",
       "      <td>0.302149</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>-0.023964</td>\n",
       "      <td>0.278636</td>\n",
       "      <td>0.156217</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121411</td>\n",
       "      <td>0.155847</td>\n",
       "      <td>0.085004</td>\n",
       "      <td>0.262969</td>\n",
       "      <td>0.099392</td>\n",
       "      <td>0.457963</td>\n",
       "      <td>0.117635</td>\n",
       "      <td>0.297306</td>\n",
       "      <td>-0.026049</td>\n",
       "      <td>-0.013435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.124747</td>\n",
       "      <td>-0.169017</td>\n",
       "      <td>-0.162681</td>\n",
       "      <td>-0.283808</td>\n",
       "      <td>-0.272176</td>\n",
       "      <td>-0.176874</td>\n",
       "      <td>0.213243</td>\n",
       "      <td>-0.160942</td>\n",
       "      <td>-0.131333</td>\n",
       "      <td>-0.487269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032140</td>\n",
       "      <td>0.330343</td>\n",
       "      <td>-0.353373</td>\n",
       "      <td>0.079498</td>\n",
       "      <td>-0.240863</td>\n",
       "      <td>-0.188980</td>\n",
       "      <td>0.074720</td>\n",
       "      <td>0.041163</td>\n",
       "      <td>-0.169618</td>\n",
       "      <td>-0.182355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.130035</td>\n",
       "      <td>-0.161746</td>\n",
       "      <td>-0.159999</td>\n",
       "      <td>-0.284987</td>\n",
       "      <td>-0.272495</td>\n",
       "      <td>-0.176450</td>\n",
       "      <td>0.219518</td>\n",
       "      <td>-0.164201</td>\n",
       "      <td>-0.139630</td>\n",
       "      <td>-0.477791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025642</td>\n",
       "      <td>0.330252</td>\n",
       "      <td>-0.373162</td>\n",
       "      <td>0.081284</td>\n",
       "      <td>-0.247350</td>\n",
       "      <td>-0.179109</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>0.036812</td>\n",
       "      <td>-0.172079</td>\n",
       "      <td>-0.166253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125885</td>\n",
       "      <td>0.135601</td>\n",
       "      <td>-0.019326</td>\n",
       "      <td>0.153458</td>\n",
       "      <td>-0.080039</td>\n",
       "      <td>0.083314</td>\n",
       "      <td>-0.293421</td>\n",
       "      <td>0.276295</td>\n",
       "      <td>0.021222</td>\n",
       "      <td>0.216001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211338</td>\n",
       "      <td>-0.310424</td>\n",
       "      <td>0.245695</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>0.244034</td>\n",
       "      <td>0.444554</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.041892</td>\n",
       "      <td>-0.132476</td>\n",
       "      <td>-0.174954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.123520</td>\n",
       "      <td>0.245146</td>\n",
       "      <td>0.137474</td>\n",
       "      <td>0.235598</td>\n",
       "      <td>0.140397</td>\n",
       "      <td>0.287948</td>\n",
       "      <td>-0.117437</td>\n",
       "      <td>0.239361</td>\n",
       "      <td>0.037772</td>\n",
       "      <td>-0.014582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100402</td>\n",
       "      <td>-0.487872</td>\n",
       "      <td>0.246989</td>\n",
       "      <td>-0.446680</td>\n",
       "      <td>-0.246674</td>\n",
       "      <td>-0.490044</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>-0.270419</td>\n",
       "      <td>-0.147116</td>\n",
       "      <td>-0.161871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.160747  0.076773  0.149212 -0.138141  0.302149  0.019053 -0.023964   \n",
       "1  0.124747 -0.169017 -0.162681 -0.283808 -0.272176 -0.176874  0.213243   \n",
       "2  0.130035 -0.161746 -0.159999 -0.284987 -0.272495 -0.176450  0.219518   \n",
       "3  0.125885  0.135601 -0.019326  0.153458 -0.080039  0.083314 -0.293421   \n",
       "4  0.123520  0.245146  0.137474  0.235598  0.140397  0.287948 -0.117437   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0  0.278636  0.156217  0.006057  ...  0.121411  0.155847  0.085004  0.262969   \n",
       "1 -0.160942 -0.131333 -0.487269  ... -0.032140  0.330343 -0.353373  0.079498   \n",
       "2 -0.164201 -0.139630 -0.477791  ... -0.025642  0.330252 -0.373162  0.081284   \n",
       "3  0.276295  0.021222  0.216001  ...  0.211338 -0.310424  0.245695  0.248740   \n",
       "4  0.239361  0.037772 -0.014582  ... -0.100402 -0.487872  0.246989 -0.446680   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0  0.099392  0.457963  0.117635  0.297306 -0.026049 -0.013435  \n",
       "1 -0.240863 -0.188980  0.074720  0.041163 -0.169618 -0.182355  \n",
       "2 -0.247350 -0.179109  0.076438  0.036812 -0.172079 -0.166253  \n",
       "3  0.244034  0.444554  0.012390  0.041892 -0.132476 -0.174954  \n",
       "4 -0.246674 -0.490044  0.206700 -0.270419 -0.147116 -0.161871  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>को</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      ▁\n",
       "4     को"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1247, -0.1690, -0.1627, -0.2838, -0.2722, -0.1769,  0.2132, -0.1609,\n",
       "        -0.1313, -0.4873,  0.0933,  0.2504, -0.1186,  0.3931,  0.1213, -0.3692,\n",
       "         0.0870, -0.3274,  0.2699, -0.2437,  0.0111,  0.4535,  0.2668,  0.0661,\n",
       "         0.3557, -0.4491,  0.0940,  0.2342, -0.0936, -0.2848,  0.0331, -0.0707,\n",
       "         0.0324, -0.1482,  0.0281,  0.0329,  0.1116, -0.0603,  0.2789, -0.1795,\n",
       "         0.0362, -0.0211,  0.2475, -0.2763, -0.0959, -0.0447,  0.3523, -0.1490,\n",
       "         0.1639, -0.0294,  0.0555, -0.0330,  0.1610, -0.2055,  0.3066, -0.0114,\n",
       "         0.1892,  0.4933,  0.1868,  0.0109,  0.1630,  0.2928, -0.3037, -0.1148,\n",
       "         0.1884,  0.0681,  0.1940, -0.1562,  0.0480, -0.4323, -0.0371,  0.0455,\n",
       "         0.0631,  0.0229, -0.0659, -0.1054,  0.1637, -0.2935,  0.2553, -0.0453,\n",
       "         0.4218, -0.1516,  0.2000, -0.0105, -0.4283,  0.0756,  0.4329,  0.2228,\n",
       "         0.0705, -0.0233,  0.0633, -0.2401, -0.2446,  0.0722,  0.0554,  0.1877,\n",
       "         0.1738,  0.1369, -0.1079, -0.3869,  0.2981,  0.0700, -0.4696,  0.3017,\n",
       "        -0.1329, -0.1050,  0.1304, -0.0410, -0.0011,  0.2185, -0.0591,  0.1141,\n",
       "        -0.0840,  0.1178,  0.4338,  0.2328,  0.0511,  0.2602, -0.2272, -0.4277,\n",
       "        -0.0819,  0.2098,  0.4179,  0.2500,  0.1381, -0.3338,  0.0817, -0.0172,\n",
       "         0.1663, -0.1604, -0.1632, -0.0647,  0.3461,  0.3764,  0.0449,  0.1591,\n",
       "        -0.0095,  0.2866, -0.0094,  0.1217,  0.0780,  0.1722,  0.2241, -0.0063,\n",
       "        -0.1501,  0.2576, -0.0262,  0.0224,  0.0574, -0.2975,  0.4385,  0.1475,\n",
       "        -0.0175,  0.4273,  0.3189, -0.1054,  0.3649, -0.3940, -0.1859,  0.1198,\n",
       "        -0.1369,  0.1253, -0.3201,  0.2003,  0.2473, -0.1532, -0.2368,  0.3936,\n",
       "         0.2221,  0.0711, -0.1180, -0.0134,  0.0275,  0.1744, -0.0924, -0.3141,\n",
       "        -0.2361, -0.0176,  0.1380, -0.2298,  0.0972, -0.0790, -0.2406, -0.2114,\n",
       "         0.0241,  0.3676, -0.2175, -0.0761,  0.2284,  0.0094, -0.0073, -0.2719,\n",
       "         0.3287,  0.1900,  0.0528, -0.1174,  0.2546, -0.0438, -0.2073, -0.3926,\n",
       "        -0.0906,  0.1543, -0.1446, -0.3253, -0.0356, -0.2487,  0.0703, -0.0725,\n",
       "        -0.1642, -0.1236, -0.2654,  0.0095, -0.2727,  0.0706,  0.2957, -0.2671,\n",
       "        -0.2763,  0.0093, -0.2887,  0.1323,  0.2323,  0.3681, -0.2724, -0.2301,\n",
       "         0.0125,  0.4331, -0.0297,  0.2666, -0.4102,  0.1695,  0.1682,  0.2560,\n",
       "         0.1578, -0.0135, -0.0452,  0.0498,  0.1050, -0.2007,  0.2231, -0.3327,\n",
       "         0.1381,  0.3940, -0.1411,  0.1010,  0.1461, -0.0339, -0.2058, -0.3030,\n",
       "         0.0875,  0.1374, -0.3170,  0.4666, -0.1615,  0.0349,  0.1936, -0.2204,\n",
       "         0.0638,  0.0820,  0.2681,  0.1507,  0.0514, -0.2357, -0.0246,  0.1165,\n",
       "         0.0250,  0.1455, -0.1802,  0.0164,  0.2740,  0.1365, -0.2464,  0.4048,\n",
       "        -0.5397, -0.0967, -0.4396,  0.0329,  0.1193, -0.2159,  0.2610, -0.0015,\n",
       "        -0.2028, -0.0729,  0.0813, -0.2462,  0.0858,  0.6288, -0.3857, -0.0610,\n",
       "        -0.0018,  0.0213,  0.0522, -0.0517,  0.0319, -0.0648,  0.6071,  0.0239,\n",
       "        -0.3121, -0.0095,  0.1202,  0.0126, -0.0030,  0.0928, -0.3064, -0.1458,\n",
       "         0.0495,  0.3815,  0.0326, -0.3153, -0.3054,  0.1417, -0.1133, -0.0741,\n",
       "         0.1078, -0.2293,  0.1580, -0.0055,  0.2131, -0.2130, -0.4444, -0.1117,\n",
       "         0.3121, -0.0596,  0.0534, -0.0584, -0.0169, -0.0675,  0.0698,  0.0872,\n",
       "         0.0598,  0.2650,  0.2265, -0.3272,  0.3929, -0.1911,  0.1493, -0.4644,\n",
       "        -0.1673,  0.0883, -0.0792, -0.1177, -0.0806, -0.0392, -0.0879,  0.0468,\n",
       "        -0.0156, -0.2888,  0.3302, -0.0671, -0.1179,  0.0764, -0.1706,  0.1344,\n",
       "        -0.0453, -0.1263,  0.2568, -0.2282,  0.0342,  0.0406, -0.4899,  0.1224,\n",
       "         0.0257,  0.2545,  0.0488,  0.4713,  0.0345, -0.1603, -0.4387, -0.3780,\n",
       "        -0.0177,  0.1439, -0.1858, -0.0398, -0.7816, -0.0246, -0.0304,  0.1701,\n",
       "        -0.1227, -0.1014, -0.1222, -0.1302,  0.0053,  0.1475,  0.0917,  0.0781,\n",
       "        -0.0505, -0.2060,  0.3137,  0.0516,  0.1498,  0.0923, -0.2507,  0.0847,\n",
       "        -0.1670,  0.3387,  0.1221, -0.1490, -0.3420,  0.1249, -0.0909,  0.0686,\n",
       "        -0.0321,  0.3303, -0.3534,  0.0795, -0.2409, -0.1890,  0.0747,  0.0412,\n",
       "        -0.1696, -0.1824], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
